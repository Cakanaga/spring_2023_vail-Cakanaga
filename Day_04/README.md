# Convolution Neural Network

## Topics covered in today's module
* Convolution neural network components
* Visualizing kernels
* Visualizing feature maps
* Pooling
* Dropout
* Batch norm

## Main takeaways from doing today's assignment

Overfitting is a phenomena that happens when your training dataset is not large enough to accomodate the number of features, that can theoretically be used for classification/prediction by the neural network model you have built to learn the prediction task.

A consequence of overfitting is that model "memorizes" the training data and is unable to generalize to the new data it sees during training. A signal that overfitting is likely happening during training is that a very high difference between training error and the test error is observed.

A purpose of pooling layers is to reduce the spatial dimensions (height and width). This has the potential to reduce overfitting --- a phenomena that happens when your dataset is not large enough to accomodate the number of features, that can theoretically be used for classification/prediction.

## Challenging, interesting, or exciting aspects of today's assignment
<To be filled>

## Additional resources used 
https://medium.com/analytics-vidhya/a-tip-a-day-python-tip-8-why-should-we-normalize-image-pixel-values-or-divide-by-255-4608ac5cd26a
